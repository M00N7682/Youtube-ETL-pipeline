"""transform.py
Transform raw YouTube API data (extracted as JSON) into structured tabular format.

This module loads one or more raw JSON files (generated by extract.py) and extracts
key fields such as video ID, title, channel, publish time, etc.

The output is stored as a normalized CSV under data/processed/

Example usage:
    python transform.py --inputs data/raw/*.json

"""

import argparse
import json
import logging
from pathlib import Path
from typing import Any, Dict, List
import pandas as pd
from datetime import datetime

# Directory paths
RAW_DIR = Path(__file__).resolve().parent.parent / "data" / "raw"
PROCESSED_DIR = Path(__file__).resolve().parent.parent / "data" / "processed"
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

# Configure logging
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

def normalize_item(item: Dict[str, Any]) -> Dict[str, Any]:
    """Extract and normalize relevant fields from a raw YouTube API item."""
    snippet = item.get("snippet", {})
    return {
        "video_id": item.get("id", {}).get("videoId"),
        "title": snippet.get("title"),
        "channel_title": snippet.get("channelTitle"),
        "published_at": snippet.get("publishedAt"),
        "description": snippet.get("description"),
        "query_tag": snippet.get("query_tag", None)  # Optional: custom tracking tag
    }

def transform_file(json_path: Path) -> pd.DataFrame:
    """Transform a single JSON file to a DataFrame."""
    with open(json_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    if isinstance(raw_data, dict):
        items = raw_data.get("items", [])
    elif isinstance(raw_data, list):
        items = raw_data
    else:
        logger.warning("Unexpected JSON format in %s", json_path)
        return pd.DataFrame()

    records = [normalize_item(item) for item in items if item.get("id", {}).get("videoId")]
    df = pd.DataFrame(records)
    logger.info("Transformed %d records from %s", len(df), json_path.name)
    return df

def save_transformed(df: pd.DataFrame, source_file: Path) -> Path:
    """Save DataFrame as CSV under data/processed/"""
    base_name = source_file.stem.replace(".json", "")
    timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H-%M-%SZ")
    out_path = PROCESSED_DIR / f"{timestamp}_{base_name}.csv"
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    logger.info("Saved transformed data to %s", out_path)
    return out_path

def run_transform(raw_paths: List[str]) -> List[str]:
    output_paths = []
    for raw_path in raw_paths:
        df = transform_file(Path(raw_path))
        if not df.empty:
            output_path = save_transformed(df, Path(raw_path))
            output_paths.append(str(output_path))
    return output_paths

# CLI usage
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Transform raw YouTube JSON to CSV")
    parser.add_argument("--inputs", nargs='+', required=True, help="List of raw JSON files")
    args = parser.parse_args()

    run_transform(args.inputs)
